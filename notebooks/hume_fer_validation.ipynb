{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hume_data(path):\n",
    "    df_facial = pd.read_csv(path, index_col=0)\n",
    "    df_facial.drop('start', axis=1, inplace=True)\n",
    "    df_facial.columns = ['hume_anger', 'hume_disgust', 'hume_fear', 'hume_joy', 'hume_sadness', 'hume_surprise', 'hume_neutral', 'start_patch']\n",
    "    df_facial['start_patch'] = df_facial['start_patch'].astype('int64')\n",
    "    df_facial = df_facial.groupby('start_patch').mean().reset_index()\n",
    "    return df_facial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_text_hume_data(df_hume, df_fer):\n",
    "    df_merged = pd.merge(df_hume, df_fer, on=['start_patch'], how='inner').drop('start_patch', axis=1)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fer_data(path):\n",
    "    df_facial = pd.read_csv(path, index_col=0)\n",
    "    #df_facial.drop('start', axis=1, inplace=True)\n",
    "    df_facial.columns = ['fer_anger', 'fer_disgust', 'fer_fear', 'fer_joy', 'fer_sadness', 'fer_surprise', 'fer_neutral', 'start_patch']\n",
    "    df_facial['start_patch'] = df_facial['start_patch'].astype('int64')\n",
    "    df_facial = df_facial.groupby('start_patch').mean().reset_index()\n",
    "    return df_facial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_csv_data(df1_name_hume, df2_name):\n",
    "    # Read the CSV files into pandas DataFrames\n",
    "    df1 = df1_name_hume\n",
    "    df2 = df2_name\n",
    "    \n",
    "    # Extract the emotion columns from each DataFrame\n",
    "    hume_emotions = ['hume_anger', 'hume_disgust', 'hume_fear', 'hume_joy', 'hume_sadness', 'hume_surprise', 'hume_neutral']\n",
    "\n",
    "    fer_emotions = ['fer_anger', 'fer_disgust', 'fer_fear', 'fer_joy', 'fer_sadness', 'fer_surprise', 'fer_neutral']\n",
    "    \n",
    "    # # Iterate over the emotion columns and plot the data for each file\n",
    "    # for emotion in hume_emotions:\n",
    "    #     plt.figure()\n",
    "    #     plt.plot(df1['hume_start_patch'], df1[emotion], label= str('hume'))\n",
    "    #     plt.xlabel('Timestamp')\n",
    "    #     plt.ylabel('Score')\n",
    "    #     plt.title('Comparison of ' + emotion)\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "\n",
    "    # for emotion in fer_emotions:\n",
    "    #     plt.figure()\n",
    "    #     plt.plot(df2['fer_start_patch'], df2[emotion], label= str('fer'))\n",
    "    #     plt.xlabel('Timestamp')\n",
    "    #     plt.ylabel('Score')\n",
    "    #     plt.title('Comparison of ' + emotion)\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(df1['start_patch'], df1['hume_anger'], label= str('hume'))\n",
    "    plt.plot(df2['start_patch'], df2['fer_anger'], label= str('fer'))\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Comparison of ' + 'Anger')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations_with_binary(df, binary_feature, continuous_features, corr_func= pearsonr ):\n",
    "    df = df.dropna()\n",
    "    correlation_data = []\n",
    "    for feature in continuous_features:\n",
    "        corr, p_value = corr_func(df[feature], df[binary_feature])\n",
    "        correlation_data.append((feature, corr, p_value))\n",
    "    \n",
    "    data = correlation_data\n",
    "    # Extract feature names, correlations, and p-values\n",
    "    features = [item[0] for item in data]\n",
    "    correlations = [item[1] for item in data]\n",
    "    p_values = [item[2] for item in data]\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the correlations as vertical bars\n",
    "    ax.bar(features, correlations, color='steelblue')\n",
    "\n",
    "    # Set the y-axis label\n",
    "    ax.set_ylabel('Correlation')\n",
    "\n",
    "    # Add horizontal gridlines\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "    # Set the title\n",
    "    ax.set_title('Correlation with Binary Variable')\n",
    "\n",
    "    # Add error bars representing p-values\n",
    "    ax.errorbar(features, correlations, yerr=np.abs(correlations), fmt='none', color='black', capsize=5, label='p-value')\n",
    "\n",
    "    # Add p-values and absolute correlation values as text annotations\n",
    "    for feature, correlation, p_value in zip(features, correlations, p_values):\n",
    "        ax.text(feature, 0, f'p={p_value:.2f}', ha='center', va='bottom')\n",
    "        ax.text(feature, correlation, f'{abs(correlation):.2f}', ha='center', va='top')\n",
    "\n",
    "    # Rotate x-axis labels for better visibility\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hume_1 = prepare_hume_data('../data/hume/processed/Cuban_vocals_afternoon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fer_1 = prepare_fer_data('../data/FER_Output/processed/Cuban_vocals_afternoon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_text_hume_data(df_hume_1, df_fer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_corr = df_merged.corr().drop(['hume_anger', 'hume_disgust', 'hume_fear', 'hume_joy', 'hume_sadness', 'hume_surprise', 'hume_neutral'], axis=1)\n",
    "df_merged_corr = df_merged_corr.drop(['fer_anger', 'fer_disgust', 'fer_fear', 'fer_joy', 'fer_sadness', 'fer_surprise', 'fer_neutral'],axis=0)\n",
    "df_merged_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_merged_corr, annot=True, cmap='coolwarm')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_csv_data(df_hume_1, df_fer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hume_2 = prepare_hume_data('../data/hume/processed/Cuban_vocals_morning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_csv_data(df_hume_2, '../data/FER_Output/processed/Cuban_vocals_morning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hume_3 = prepare_hume_data('../data/hume/processed/Funk_band_morning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_csv_data(df_hume_3, '../data/FER_Output/processed/Funk_band_morning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hume_4 = prepare_hume_data('../data/hume/processed/Funk_rhythm_morning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_csv_data(df_hume_4, '../data/FER_Output/processed/Funk_rhythm_morning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation by comparing the max feature for each time slot of 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hume_data(path, var_neutral):\n",
    "    df_facial = pd.read_csv(path, index_col=0)\n",
    "    df_facial.drop('start', axis=1, inplace=True)\n",
    "    df_facial.columns = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral', 'start_patch']\n",
    "    df_facial['start_patch'] = df_facial['start_patch'].astype('int64')\n",
    "    df_facial = df_facial.groupby('start_patch').mean().reset_index()\n",
    "    if var_neutral == True:\n",
    "        df_facial = df_facial.drop(columns=['start_patch'])\n",
    "    else:\n",
    "        df_facial = df_facial.drop(columns=['start_patch', 'neutral'])\n",
    "    return df_facial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fer_data(path, var_neutral):\n",
    "    df_facial = pd.read_csv(path, index_col=0)\n",
    "    #df_facial.drop('start', axis=1, inplace=True)\n",
    "    df_facial.columns = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral', 'start_patch']\n",
    "    df_facial['start_patch'] = df_facial['start_patch'].astype('int64')\n",
    "    df_facial = df_facial.groupby('start_patch').mean().reset_index()\n",
    "    if var_neutral == True:\n",
    "        df_facial = df_facial.drop(columns=['start_patch'])\n",
    "    else:\n",
    "        df_facial = df_facial.drop(columns=['start_patch', 'neutral'])\n",
    "    return df_facial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_to_flow_nonflow(df_merged_cleaned, var_neutral):\n",
    "    flow_emotions = ['joy', 'fear', 'surprise']\n",
    "    if var_neutral == True:\n",
    "        non_flow =['neutral', 'sadness', 'anger']\n",
    "    else:\n",
    "        non_flow =['disgust', 'sadness', 'anger']\n",
    "    #df_merged_cleaned = df_merged.drop(['segment_id', 'start', 'end', 'negative'], axis=1)\n",
    "    df_merged_cleaned= df_merged_cleaned.dropna(axis=0)\n",
    "    df_merged_cleaned\n",
    "    df_merged_cleaned['flow_emotions'] = df_merged_cleaned[flow_emotions].mean(axis=1)\n",
    "    df_merged_cleaned['non_flow_emotions'] = df_merged_cleaned[non_flow].mean(axis=1)\n",
    "\n",
    "    if var_neutral == True:\n",
    "        df_merged_cleaned = df_merged_cleaned.drop(columns=['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'])\n",
    "    else:\n",
    "        df_merged_cleaned = df_merged_cleaned.drop(columns=['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise'])\n",
    "\n",
    "    \n",
    "\n",
    "    return df_merged_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_with_icolumns(num_columns):\n",
    "    column_names = [f'Column{i}' for i in range(1, num_columns + 1)]\n",
    "    df_new = pd.DataFrame(columns=column_names)    \n",
    "    \n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_max_score_to_array(df_aggregated_to_flow_non_flow, df_scores, num_max_scores):\n",
    "    scores = []\n",
    "    for index, row in df_aggregated_to_flow_non_flow.iterrows():\n",
    "        max_score = row.nlargest(num_max_scores)\n",
    "        df_scores.loc[index] = max_score.index\n",
    "\n",
    "    # Iterate over each row in the dataframe\n",
    "    for _, row in df_scores.iterrows():\n",
    "        # Convert the row to a list and append it to the row_array\n",
    "        scores.append(row.tolist())\n",
    "    \n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_hume_fer(scores_hume, scores_fer):\n",
    "    # Check if the length of the arrays is the same\n",
    "    if len(scores_hume) == len(scores_fer):\n",
    "        # Initialize a count variable to keep track of matching elements\n",
    "        count = 0\n",
    "\n",
    "        # Iterate over the arrays using zip()\n",
    "        for element1, element2 in zip(scores_hume, scores_fer):\n",
    "            # Compare the elements from both arrays\n",
    "            if element1 == element2:\n",
    "                #print(f\"Elements match: {element1}\")\n",
    "                count += 1\n",
    "            else:\n",
    "                #print(f\"Elements do not match: {element1} and {element2}\")\n",
    "                count+= 0\n",
    "\n",
    "        # Calculate the percentage of matching elements\n",
    "        percentage = (count / len(scores_hume)) * 100\n",
    "        print(f\"Percentage of matching elements: {percentage}%\")\n",
    "    else:\n",
    "        print(\"Arrays have different lengths.\")\n",
    "\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_arrays_and_delete(arr1, arr2):\n",
    "    if len(arr1) > len(arr2):\n",
    "        del arr1[len(arr2):]\n",
    "    elif len(arr2) > len(arr1):\n",
    "        del arr2[len(arr1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hume_fer_validation(hume_path, fer_path, num_columns, aggregation, var_neutral):\n",
    "    df_hume = prepare_hume_data(hume_path, var_neutral)\n",
    "    df_fer = prepare_fer_data(fer_path, var_neutral)\n",
    "\n",
    "    if aggregation == True:\n",
    "        df_hume_agg = aggregate_to_flow_nonflow(df_hume, var_neutral)\n",
    "        df_fer_agg = aggregate_to_flow_nonflow(df_fer, var_neutral)\n",
    "\n",
    "        df_hume_scores = create_dataframe_with_icolumns(num_columns)\n",
    "        df_fer_scores = create_dataframe_with_icolumns(num_columns)\n",
    "\n",
    "        hume_scores = select_max_score_to_array(df_hume_agg, df_hume_scores, num_columns)\n",
    "        fer_scores = select_max_score_to_array(df_fer_agg, df_fer_scores, num_columns)\n",
    "\n",
    "    else:\n",
    "        df_hume_scores = create_dataframe_with_icolumns(num_columns)\n",
    "        df_fer_scores = create_dataframe_with_icolumns(num_columns)\n",
    "\n",
    "        hume_scores = select_max_score_to_array(df_hume, df_hume_scores, num_columns)\n",
    "        fer_scores = select_max_score_to_array(df_fer, df_fer_scores, num_columns)\n",
    "\n",
    "    compare_arrays_and_delete(hume_scores, fer_scores)\n",
    "\n",
    "    overall_score = validate_hume_fer(hume_scores, fer_scores)\n",
    "\n",
    "    return overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_incl_neutral_agg = []\n",
    "number_max_elements = 1\n",
    "var_aggregation = True\n",
    "var_neutral = True\n",
    "\n",
    "score_incl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "score_incl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(score_incl_neutral_agg)/len(score_incl_neutral_agg)\n",
    "\n",
    "print(f\"Aggregation including neutral: {validation}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_excl_neutral_agg = []\n",
    "number_max_elements = 1\n",
    "var_aggregation = True\n",
    "var_neutral = False\n",
    "\n",
    "score_excl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "score_excl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_agg.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(score_excl_neutral_agg)/len(score_excl_neutral_agg)\n",
    "\n",
    "print(f\"Aggregation exluding neutral: {validation}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_incl_neutral = []\n",
    "number_max_elements = 1\n",
    "var_aggregation = False\n",
    "var_neutral = True\n",
    "\n",
    "score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(score_incl_neutral)/len(score_incl_neutral)\n",
    "\n",
    "print(f\"Max Emotion value with neutral: {validation}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_excl_neutral = []\n",
    "number_max_elements = 1\n",
    "var_aggregation = False\n",
    "var_neutral = False\n",
    "\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(score_excl_neutral)/len(score_excl_neutral)\n",
    "\n",
    "print(f\"Max Emotion value without neutral: {validation}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_excl_neutral = []\n",
    "number_max_elements = 1\n",
    "var_aggregation = False\n",
    "var_neutral = False\n",
    "\n",
    "#score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(score_excl_neutral)/len(score_excl_neutral)\n",
    "\n",
    "print(f\"Max Emotion value without neutral and without first video: {validation}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_excl_neutral_wo1 = []\n",
    "number_max_elements = 1\n",
    "var_aggregation = False\n",
    "var_neutral = False\n",
    "\n",
    "score_excl_neutral_wo1.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "score_excl_neutral_wo1.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_wo1.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_wo1.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_wo1.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "score_excl_neutral_wo1.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(score_excl_neutral_wo1)/len(score_excl_neutral_wo1)\n",
    "\n",
    "print(f\"Max Emotion value without neutral and without first video: {validation}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of matching elements: 9.67741935483871%\n",
      "Percentage of matching elements: 18.75%\n",
      "Percentage of matching elements: 6.25%\n",
      "Percentage of matching elements: 3.3333333333333335%\n",
      "Percentage of matching elements: 0.0%\n",
      "Percentage of matching elements: 3.8461538461538463%\n",
      "Two Max Emotion values without neutral: 6.976151089054316%\n"
     ]
    }
   ],
   "source": [
    "two_score_excl_neutral = []\n",
    "number_max_elements = 2\n",
    "var_aggregation = False\n",
    "var_neutral = False\n",
    "\n",
    "two_score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "two_score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_excl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(two_score_excl_neutral)/len(two_score_excl_neutral)\n",
    "\n",
    "print(f\"Two Max Emotion values without neutral: {validation}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of matching elements: 9.67741935483871%\n",
      "Percentage of matching elements: 12.5%\n",
      "Percentage of matching elements: 3.125%\n",
      "Percentage of matching elements: 6.666666666666667%\n",
      "Percentage of matching elements: 0.0%\n",
      "Percentage of matching elements: 3.8461538461538463%\n",
      "Two Max Emotion values with neutral: 5.96920664460987%\n"
     ]
    }
   ],
   "source": [
    "two_score_incl_neutral = []\n",
    "number_max_elements = 2\n",
    "var_aggregation = False\n",
    "var_neutral = True\n",
    "\n",
    "two_score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_afternoon.csv','../data/FER_Output/processed/Cuban_vocals_afternoon.csv', number_max_elements, var_aggregation, var_neutral ))\n",
    "two_score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Cuban_vocals_morning.csv', '../data/FER_Output/processed/Cuban_vocals_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_afternoon.csv', '../data/FER_Output/processed/Funk_band_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_band_morning.csv', '../data/FER_Output/processed/Funk_band_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_afternoon.csv', '../data/FER_Output/processed/Funk_rhythm_afternoon.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "two_score_incl_neutral.append(hume_fer_validation('../data/hume/processed/Funk_rhythm_morning.csv', '../data/FER_Output/processed/Funk_rhythm_morning.csv', number_max_elements,var_aggregation, var_neutral))\n",
    "\n",
    "validation = sum(two_score_incl_neutral)/len(two_score_incl_neutral)\n",
    "\n",
    "print(f\"Two Max Emotion values with neutral: {validation}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe: Nochmal tiefer in die Emotionen reingehen, neutral rauswerfen und f端r die einzelen max emotionen gucken ob 端bereinstimmt oder zwei oder drei. Dann Ergebnis nochmal f端r alle Videos machen und vielleicht auch durchschnitt bilden f端r Paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COIN_Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
